#!/usr/bin/env python3
"""
æµ‹è¯•ç®€åŒ–çš„å»¶è¿Ÿç¼–ç å®ç°
åŸºäºæ—¶é—´å»¶è¿Ÿçš„é«˜æ•ˆå®ç°
"""

import torch
import numpy as np
import matplotlib.pyplot as plt

def simple_latency_encode(x, time_steps=100):
    """
    ç®€åŒ–çš„å»¶è¿Ÿç¼–ç ï¼šä¿¡å·å¼ºåº¦å†³å®šå‘æ”¾æ—¶é—´
    x: è¾“å…¥ä¿¡å·å¼ é‡ [0,1]ï¼Œå€¼è¶Šå¤§å»¶è¿Ÿè¶ŠçŸ­
    time_steps: æ—¶é—´çª—å£é•¿åº¦
    è¿”å›: è„‰å†²æ—¶é—´åºåˆ—å¼ é‡ [batch_size, time_steps] æˆ– [time_steps]
    """
    # è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼šä¿¡å·è¶Šå¼ºï¼Œå»¶è¿Ÿè¶ŠçŸ­
    # delay = (1 - x) * (time_steps - 1)ï¼ŒèŒƒå›´[0, time_steps-1]
    delays = ((1.0 - x.clamp(0, 1)) * (time_steps - 1)).long()
    
    # åˆ›å»ºè¾“å‡ºå¼ é‡
    if x.dim() == 0:  # æ ‡é‡
        spikes = torch.zeros(time_steps, dtype=x.dtype, device=x.device)
        spikes[delays] = 1.0
    elif x.dim() == 1:  # 1Då¼ é‡
        spikes = torch.zeros(len(x), time_steps, dtype=x.dtype, device=x.device)
        for i, delay in enumerate(delays):
            spikes[i, delay] = 1.0
    else:  # å¤šç»´å¼ é‡
        batch_shape = x.shape
        spikes = torch.zeros(*batch_shape, time_steps, dtype=x.dtype, device=x.device)
        flat_x = x.flatten()
        flat_delays = delays.flatten()
        flat_spikes = spikes.view(-1, time_steps)
        
        for i, delay in enumerate(flat_delays):
            flat_spikes[i, delay] = 1.0
            
    return spikes

def simple_latency_encode_with_noise(x, time_steps=100, noise_std=0.1):
    """
    å¸¦å™ªå£°çš„å»¶è¿Ÿç¼–ç ï¼šæ·»åŠ æ—¶é—´æŠ–åŠ¨ä»¥å¢åŠ é²æ£’æ€§
    x: è¾“å…¥ä¿¡å·å¼ é‡ [0,1]
    time_steps: æ—¶é—´çª—å£é•¿åº¦  
    noise_std: æ—¶é—´å™ªå£°æ ‡å‡†å·®ï¼ˆç›¸å¯¹äºtime_stepsï¼‰
    è¿”å›: è„‰å†²æ—¶é—´åºåˆ—å¼ é‡
    """
    # åŸºç¡€å»¶è¿Ÿ
    base_delays = (1.0 - x.clamp(0, 1)) * (time_steps - 1)
    
    # æ·»åŠ é«˜æ–¯å™ªå£°
    noise = torch.randn_like(base_delays) * noise_std * time_steps
    noisy_delays = (base_delays + noise).clamp(0, time_steps - 1).long()
    
    # ç”Ÿæˆè„‰å†²
    if x.dim() == 0:
        spikes = torch.zeros(time_steps, dtype=x.dtype, device=x.device)
        spikes[noisy_delays] = 1.0
    elif x.dim() == 1:
        spikes = torch.zeros(len(x), time_steps, dtype=x.dtype, device=x.device)
        for i, delay in enumerate(noisy_delays):
            spikes[i, delay] = 1.0
    else:
        batch_shape = x.shape
        spikes = torch.zeros(*batch_shape, time_steps, dtype=x.dtype, device=x.device)
        flat_delays = noisy_delays.flatten()
        flat_spikes = spikes.view(-1, time_steps)
        
        for i, delay in enumerate(flat_delays):
            flat_spikes[i, delay] = 1.0
            
    return spikes

def simple_latency_decode(spikes):
    """
    ç®€åŒ–çš„å»¶è¿Ÿè§£ç ï¼šä»å‘æ”¾æ—¶é—´æ¢å¤ä¿¡å·å¼ºåº¦
    spikes: è„‰å†²æ—¶é—´åºåˆ— [..., time_steps]
    è¿”å›: è§£ç çš„ä¿¡å·å€¼ [0,1]
    """
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªè„‰å†²çš„ä½ç½®
    spike_times = torch.argmax(spikes.float(), dim=-1)
    time_steps = spikes.shape[-1]
    
    # è½¬æ¢å›ä¿¡å·å€¼ï¼šdelay = (1-x)*(time_steps-1) => x = 1 - delay/(time_steps-1)
    decoded = 1.0 - spike_times.float() / (time_steps - 1)
    
    # å¤„ç†æ²¡æœ‰è„‰å†²çš„æƒ…å†µï¼ˆå…¨é›¶ï¼‰
    no_spike_mask = spikes.sum(dim=-1) == 0
    decoded[no_spike_mask] = 0.0
    
    return decoded.clamp(0, 1)

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½")
    
    # æµ‹è¯•æ•°æ®ï¼šä¸åŒçš„ä¿¡å·å¼ºåº¦
    signals = torch.tensor([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])
    time_steps = 10
    
    print(f"è¾“å…¥ä¿¡å·: {signals}")
    
    # ç¼–ç 
    spikes = simple_latency_encode(signals, time_steps)
    print(f"è¾“å‡ºå½¢çŠ¶: {spikes.shape}")
    
    # æ˜¾ç¤ºæ¯ä¸ªä¿¡å·çš„å‘æ”¾æ—¶é—´
    for i, signal in enumerate(signals):
        spike_time = torch.argmax(spikes[i])
        print(f"ä¿¡å· {signal:.1f} -> å»¶è¿Ÿ {spike_time} æ­¥")
    
    # è§£ç æµ‹è¯•
    decoded = simple_latency_decode(spikes)
    print(f"è§£ç ç»“æœ: {decoded}")
    print(f"é‡å»ºè¯¯å·®: {torch.abs(signals - decoded)}")
    
    return True

def test_encoding_properties():
    """æµ‹è¯•ç¼–ç ç‰¹æ€§"""
    print("\nğŸ§ª æµ‹è¯•2: ç¼–ç ç‰¹æ€§")
    
    time_steps = 50
    
    # å¼ºä¿¡å·åº”è¯¥æ—©å‘æ”¾
    strong_signal = torch.tensor(0.9)
    weak_signal = torch.tensor(0.1)
    
    strong_spikes = simple_latency_encode(strong_signal, time_steps)
    weak_spikes = simple_latency_encode(weak_signal, time_steps)
    
    strong_time = torch.argmax(strong_spikes)
    weak_time = torch.argmax(weak_spikes)
    
    print(f"å¼ºä¿¡å·({strong_signal:.1f})å‘æ”¾æ—¶é—´: {strong_time}")
    print(f"å¼±ä¿¡å·({weak_signal:.1f})å‘æ”¾æ—¶é—´: {weak_time}")
    
    early_firing = strong_time < weak_time
    print(f"å¼ºä¿¡å·æ¯”å¼±ä¿¡å·æ—©å‘æ”¾: {'âœ…' if early_firing else 'âŒ'}")
    
    return early_firing

def test_batch_processing():
    """æµ‹è¯•æ‰¹å¤„ç†"""
    print("\nğŸ§ª æµ‹è¯•3: æ‰¹å¤„ç†")
    
    # æ¨¡æ‹Ÿç¥ç»ç½‘ç»œè¾“å…¥ï¼š(batch_size, features)
    batch_size, features = 3, 5
    time_steps = 20
    
    # éšæœºä¿¡å·
    torch.manual_seed(42)
    signals = torch.rand(batch_size, features)
    
    print(f"è¾“å…¥å½¢çŠ¶: {signals.shape}")
    print(f"ä¿¡å·èŒƒå›´: [{signals.min():.3f}, {signals.max():.3f}]")
    
    # ç¼–ç 
    spikes = simple_latency_encode(signals, time_steps)
    
    print(f"è¾“å‡ºå½¢çŠ¶: {spikes.shape}")
    print(f"æ¯ä¸ªç¥ç»å…ƒå‘æ”¾ä¸€æ¬¡è„‰å†²: {(spikes.sum(dim=-1) == 1).all()}")
    
    # è§£ç 
    decoded = simple_latency_decode(spikes)
    reconstruction_error = torch.nn.functional.mse_loss(signals, decoded)
    
    print(f"é‡å»ºè¯¯å·®(MSE): {reconstruction_error:.6f}")
    
    return reconstruction_error < 0.01  # å°è¯¯å·®å®¹å¿

def test_noise_robustness():
    """æµ‹è¯•å™ªå£°é²æ£’æ€§"""
    print("\nğŸ§ª æµ‹è¯•4: å™ªå£°é²æ£’æ€§")
    
    signals = torch.tensor([0.2, 0.5, 0.8])
    time_steps = 30
    
    print(f"åŸå§‹ä¿¡å·: {signals}")
    
    # æ— å™ªå£°ç¼–ç 
    torch.manual_seed(42)
    clean_spikes = simple_latency_encode(signals, time_steps)
    clean_decoded = simple_latency_decode(clean_spikes)
    
    # æœ‰å™ªå£°ç¼–ç 
    torch.manual_seed(42)
    noisy_spikes = simple_latency_encode_with_noise(signals, time_steps, noise_std=0.05)
    noisy_decoded = simple_latency_decode(noisy_spikes)
    
    print(f"æ— å™ªå£°è§£ç : {clean_decoded}")
    print(f"æœ‰å™ªå£°è§£ç : {noisy_decoded}")
    
    clean_error = torch.abs(signals - clean_decoded).mean()
    noisy_error = torch.abs(signals - noisy_decoded).mean()
    
    print(f"æ— å™ªå£°è¯¯å·®: {clean_error:.4f}")
    print(f"æœ‰å™ªå£°è¯¯å·®: {noisy_error:.4f}")
    
    return noisy_error < 0.1  # å™ªå£°ä¸‹ä»æœ‰åˆç†ç²¾åº¦

## ä¹‹å‰åˆ°ç»ˆç«¯çš„æ–¹æ³•
# def visualize_encoding():
#     """å¯è§†åŒ–ç¼–ç ç»“æœ"""
#     print("\nğŸ§ª æµ‹è¯•5: å¯è§†åŒ–")
    
#     # ä¸åŒå¼ºåº¦çš„ä¿¡å·
#     signals = torch.tensor([0.1, 0.3, 0.5, 0.7, 0.9])
#     time_steps = 20
    
#     print("å»¶è¿Ÿç¼–ç å¯è§†åŒ–:")
#     print("ä¿¡å·  å»¶è¿Ÿæ¨¡å¼")
#     print("-" * 30)
    
#     spikes = simple_latency_encode(signals, time_steps)
    
#     for i, signal in enumerate(signals):
#         # è½¬æ¢ä¸ºå¯è§†åŒ–å­—ç¬¦
#         pattern = ''.join(['â–ˆ' if s > 0 else 'Â·' for s in spikes[i]])
#         spike_time = torch.argmax(spikes[i]).item()
        
#         print(f"{signal:.1f}   {pattern} (t={spike_time})")
    
#     return True

## doubaoçš„æ–¹æ³•
# def visualize_encoding():
#     """å¯è§†åŒ–ç¼–ç ç»“æœä¸ºå›¾ç‰‡"""
#     print("\nğŸ§ª æµ‹è¯•5: å¯è§†åŒ–")
    
#     # ä¸åŒå¼ºåº¦çš„ä¿¡å·
#     signals = torch.tensor([0.1, 0.3, 0.5, 0.7, 0.9])
#     time_steps = 20
    
#     # ç”Ÿæˆå»¶è¿Ÿç¼–ç è„‰å†²
#     spikes = simple_latency_encode(signals, time_steps)
    
#     # åˆ›å»ºæ–‡æœ¬å†…å®¹
#     text_content = [
#         "Latency Encoding Pattern (20 time steps):",
#         ""
#     ]
    
#     # ç®€æ´çš„è¡¨å¤´
#     text_content.extend([
#         "ENCODING RESULTS:",
#         "â”€" * 50,
#         "Sample  Value  Spike Time    Pattern",
#         "â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€"
#     ])
    
#     # ç”Ÿæˆæ•°æ®è¡Œ
#     for sample in range(len(signals)):
#         spike_pattern = ''.join(['â–ˆ' if s > 0 else 'Â·' for s in spikes[sample]])
#         spike_time = torch.argmax(spikes[sample]).item()
        
#         text_content.append(
#             f"{sample:>6}  {signals[sample]:>5.1f}  {spike_time:>10}    {spike_pattern}"
#         )

#     # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
#     text_content.extend(["", "Statistical Summary:", "â”€" * 50])
#     total_spikes = spikes.sum().item()
#     avg_spikes = total_spikes / len(signals)
#     text_content.append(f"Total spikes: {int(total_spikes)}")
#     text_content.append(f"Average spikes per sample: {avg_spikes:.1f}")
#     text_content.append(f"Spike efficiency: 1 spike per sample (fixed)")

#     # åŠ¨æ€è®¡ç®—å›¾ç‰‡å°ºå¯¸
#     text_lines = len(text_content)
#     max_char = max(len(line) for line in text_content)
#     font_size = 11
    
#     # è®¡ç®—é€‚åˆçš„ç”»å¸ƒå°ºå¯¸
#     fig_width = (max_char / 10) + 0.5  # ç­‰å®½å­—ä½“å­—ç¬¦å®½åº¦ä¼°ç®—
#     fig_height = (text_lines / 15) + 0.5  # ç­‰å®½å­—ä½“è¡Œé«˜ä¼°ç®—
    
#     # åˆ›å»ºç”»å¸ƒ
#     fig, ax = plt.subplots(figsize=(fig_width, fig_height))
#     ax.set_facecolor('#f8f9fa')  # æµ…ç°è‰²èƒŒæ™¯
#     ax.axis('off')  # éšè—åæ ‡è½´

#     # åœ¨å›¾ç‰‡ä¸­æ˜¾ç¤ºæ–‡æœ¬
#     ax.text(0.00, 1.00, '\n'.join(text_content), transform=ax.transAxes,
#             verticalalignment='top', fontsize=font_size, 
#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.95,
#                      edgecolor='#cccccc'))
    
#     # ä¿å­˜å›¾ç‰‡
#     plt.tight_layout()
#     plt.savefig('latency_encoding_visualization.pdf', dpi=300, bbox_inches='tight', 
#                 facecolor=fig.get_facecolor(), edgecolor='none')
#     plt.savefig('latency_encoding_visualization.png', dpi=600, bbox_inches='tight',
#                 facecolor=fig.get_facecolor(), edgecolor='none')
#     plt.close()
    
#     print("å·²ç”Ÿæˆå»¶è¿Ÿç¼–ç å¯è§†åŒ–å›¾ç‰‡: latency_encoding_visualization.pdf/png")
#     return True

## deepseekçš„æ–¹æ³•
# def visualize_encoding():
#     """Generate high-quality image for latency encoding visualization (English only)"""
#     # Test data for latency encoding
#     signals = torch.tensor([0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0])
#     time_steps = 20
    
#     # Generate latency encoding spikes
#     spikes = simple_latency_encode(signals, time_steps)
    
#     # Set professional style
#     plt.rcParams['font.family'] = 'DejaVu Sans Mono'
#     plt.rcParams['font.size'] = 11
    
#     # Create text content
#     text_content = [
#         "Latency Encoding Pattern (20 time steps):",
#         "Method: spike_time = (1 - input_value) Ã— (time_steps - 1)",
#         ""
#     ]
    
#     # Header with latency-specific information
#     text_content.extend([
#         "ENCODING RESULTS:",
#         "â”€" * 70,
#         "Sample  Value  Latency  Spike Time  Pattern",
#         "â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€"
#     ])
    
#     # Data rows with latency information
#     for sample in range(len(signals)):
#         spike_pattern = ''.join(['â–ˆ' if s > 0 else 'Â·' for s in spikes[sample]])
#         spike_time = torch.argmax(spikes[sample]).item()
#         latency = (1.0 - signals[sample].item())  # Normalized latency [0,1]
        
#         text_content.append(
#             f"{sample:>6}  {signals[sample]:>5.1f}  {latency:>7.2f}  {spike_time:>10d}    {spike_pattern}"
#         )

#     # Statistical analysis specific to latency encoding
#     text_content.extend(["", "STATISTICAL ANALYSIS:", "â”€" * 70])
#     total_spikes = spikes.sum().item()
#     avg_latency = torch.argmax(spikes.float(), dim=1).float().mean().item()
#     time_efficiency = (time_steps - avg_latency) / time_steps  # Early firing efficiency
    
#     text_content.append(f"Total spikes: {int(total_spikes)} (one spike per neuron)")
#     text_content.append(f"Average latency: {avg_latency:.1f} time steps")
#     text_content.append(f"Time efficiency: {time_efficiency:.1%} (early firing advantage)")
#     text_content.append(f"Energy consumption: {len(signals)} spikes total")
    
#     # Latency encoding characteristics
#     text_content.extend([
#         "",
#         "ENCODING CHARACTERISTICS:",
#         "â”€" * 70,
#         "âœ“ Single spike per input signal",
#         "âœ“ Earlier firing for stronger inputs", 
#         "âœ“ Fixed energy consumption regardless of input values",
#         "âœ“ Temporal coding preserves precise amplitude information",
#         "âœ“ Suitable for fast decision-making applications"
#     ])

#     # Dynamic figure size calculation
#     text_lines = len(text_content)
#     max_char = max(len(line) for line in text_content)
#     fig_width = (max_char / 10) + 1.0  # Wider for additional columns
#     fig_height = (text_lines / 14) + 0.8
    
#     # Create figure
#     fig, ax = plt.subplots(figsize=(fig_width, fig_height))
#     ax.set_facecolor('#f8f9fa')
#     ax.axis('off')

#     # Display text
#     ax.text(0.02, 0.98, '\n'.join(text_content), transform=ax.transAxes,
#             verticalalignment='top', fontsize=10,
#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.95,
#                      edgecolor='#cccccc', pad=12),
#             linespacing=1.1)
    
#     # Professional title
#     ax.text(0.5, 0.98, 'Latency (Time-to-First-Spike) Encoding Analysis', 
#             transform=ax.transAxes, horizontalalignment='center',
#             fontsize=12, fontweight='bold', fontfamily='DejaVu Sans',
#             bbox=dict(boxstyle='round', facecolor='#2E5D7A', alpha=0.9, 
#                      edgecolor='#1a3a5a', linewidth=2, pad=8),
#             color='white')
    
#     # Save high-quality images
#     plt.tight_layout()
#     plt.savefig('latency_encoding_analysis.pdf', dpi=300, bbox_inches='tight', 
#                 facecolor='white', edgecolor='none')
#     plt.savefig('latency_encoding_analysis.png', dpi=600, bbox_inches='tight',
#                 facecolor='white', edgecolor='none')
#     plt.close()
    
#     print("Generated latency encoding analysis: latency_encoding_analysis.pdf/png")
    
#     # Terminal output for verification
#     print(f"\nLatency Encoding Statistics:")
#     print(f"Signals: {len(signals)}")
#     print(f"Time steps: {time_steps}")
#     print(f"Total spikes: {int(total_spikes)}")
#     print(f"Average latency: {avg_latency:.1f} steps")
#     print(f"Time efficiency: {time_efficiency:.1%}")
    
#     # Show latency progression
#     print(f"\nLatency progression:")
#     for sample in range(len(signals)):
#         spike_time = torch.argmax(spikes[sample]).item()
#         print(f"Value {signals[sample]:.1f} -> Spike at t={spike_time}")
    
#     return True

## augumentçš„æ–¹æ³• ä¸å¯¹ï¼Œæ²¡å­¦åˆ°
# def visualize_encoding():
#     """Generate high-quality image with terminal-style output (English only)"""
#     # Test data
#     # data = np.array([[0.0], [0.1],[0.3], [0.5], [0.7], [0.9], [1.0]])
#     # spikes = encode_poisson_rate_test(data, time_steps=20, seed=42)
#     signals = torch.tensor([0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0])
#     time_steps = 20
#     spikes = simple_latency_encode(signals, time_steps)
    
#     # Set style - mimic terminal appearance
#     plt.rcParams['font.family'] = 'DejaVu Sans Mono'
#     plt.rcParams['font.size'] = 11
    
#     # Create text content in English
#     text_content = [
#         "Poisson Encoding Pattern (20 time steps):",
#         ""
#     ]
    
#     # ç®€æ´çš„è¡¨å¤´
#     text_content.extend([
#         "",
#         "ENCODING RESULTS:",
#         "â”€" * 50,
#         "Sample  Value  Spikes    Pattern",
#         "â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€"
#     ])
    
#     # ç®€æ´çš„æ•°æ®è¡Œ
#     for sample in range(data.shape[0]):
#         spike_pattern = ''.join(['â–ˆ' if s > 0 else 'Â·' for s in spikes[sample, 0, :]])
#         count = int(np.sum(spikes[sample, 0, :]))
        
#         text_content.append(
#             f"{sample:>6}  {data[sample,0]:>5.1f}  {count:>3d}/{20}    {spike_pattern}"
#         )

#     # Add statistics
#     text_content.extend(["", "Statistical Summary:", "â”€" * 50])
#     total_spikes = np.sum(spikes)
#     avg_rate = total_spikes / len(data) / 20
#     text_content.append(f"Total spikes: {int(total_spikes)}")
#     text_content.append(f"Spike sparsity: {avg_rate*100:.1f}%")
#     text_content.append(f"Bit Efficiency: {total_spikes/(len(data)*32)*100:.1f}%")

#     # åŠ¨æ€è®¡ç®—figsize
#     text_lines = len(text_content)
#     max_char = max(len(line) for line in text_content)
    
#     fig_width = (max_char / 10) + 0.5  
#     fig_height = (text_lines / 15) + 0.5  
    
#     # åˆ›å»ºç”»å¸ƒ
#     fig, ax = plt.subplots(figsize=(fig_width, fig_height))
#     ax.set_facecolor('#f8f9fa')
#     ax.axis('off') 

#     # Display text in the figure
#     ax.text(0.00, 1.00, '\n'.join(text_content), transform=ax.transAxes,
#             verticalalignment='top', fontsize=11, 
#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.95,
#                      edgecolor='#cccccc'))
    
#     # Save high-quality images
#     plt.tight_layout()
#     plt.savefig('terminal_output_style.pdf', dpi=300, bbox_inches='tight', 
#                 facecolor=fig.get_facecolor(), edgecolor='none')
#     plt.savefig('terminal_output_style.png', dpi=600, bbox_inches='tight',
#                 facecolor=fig.get_facecolor(), edgecolor='none')
#     plt.close()
    
#     # è¾“å‡ºåˆ°å›¾ç‰‡è€Œä¸æ˜¯ç»ˆç«¯
#     print("Generated terminal-style output image: terminal_output_style.pdf/png")

## Copilot Grokçš„æ–¹æ³•
def visualize_encoding():
    """Generate high-quality image with terminal-style output for latency encoding"""
    # Test data
    signals = torch.tensor([0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0])
    time_steps = 20
    
    # Generate spikes using latency encoding
    spikes = simple_latency_encode(signals, time_steps)
    
    # Set style - mimic terminal appearance
    plt.rcParams['font.family'] = 'DejaVu Sans Mono'
    plt.rcParams['font.size'] = 11
    
    # Create text content in English
    text_content = [
        "Latency Encoding Pattern (20 time steps):",
        ""
    ]
    
    # Table header
    text_content.extend([
        "",
        "ENCODING RESULTS:",
        "â”€" * 50,
        "Sample  Value  Spike Time  Pattern",
        "â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€"
    ])
    
    # Data rows
    for sample in range(len(signals)):
        spike_pattern = ''.join(['â–ˆ' if s > 0 else 'Â·' for s in spikes[sample]])
        spike_time = torch.argmax(spikes[sample]).item()
        
        text_content.append(
            f"{sample:>6}  {signals[sample]:>5.1f}  {spike_time:>9d}    {spike_pattern}"
        )

    # Add statistics
    text_content.extend(["", "Statistical Summary:", "â”€" * 50])
    total_spikes = spikes.sum().item()
    avg_spike_time = torch.argmax(spikes.float(), dim=1).float().mean().item()
    text_content.append(f"Total spikes: {int(total_spikes)}")
    text_content.append(f"Average spike time: {avg_spike_time:.1f}")
    text_content.append(f"Spike sparsity: {(total_spikes / (len(signals) * time_steps)) * 100:.1f}%")

    # Dynamic figsize
    text_lines = len(text_content)
    max_char = max(len(line) for line in text_content)
    
    fig_width = (max_char / 10) + 0.5
    fig_height = (text_lines / 15) + 0.5
    
    # Create figure
    fig, ax = plt.subplots(figsize=(fig_width, fig_height))
    ax.set_facecolor('#f8f9fa')
    ax.axis('off')

    # Display text
    ax.text(0.00, 1.00, '\n'.join(text_content), transform=ax.transAxes,
            verticalalignment='top', fontsize=11,
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.95,
                     edgecolor='#cccccc'))
    
    # Save images
    plt.tight_layout()
    plt.savefig('latency_terminal_style.pdf', dpi=300, bbox_inches='tight',
                facecolor=fig.get_facecolor(), edgecolor='none')
    plt.savefig('latency_terminal_style.png', dpi=600, bbox_inches='tight',
                facecolor=fig.get_facecolor(), edgecolor='none')
    plt.close()
    
    print("Generated latency encoding terminal-style image: latency_terminal_style.pdf/png")

def compare_with_poisson():
    """ä¸æ³Šæ¾ç¼–ç å¯¹æ¯”"""
    print("\nğŸ§ª æµ‹è¯•6: ä¸æ³Šæ¾ç¼–ç å¯¹æ¯”")
    
    def simple_poisson_encode(x):
        return torch.rand_like(x).le(x).to(x)
    
    signals = torch.tensor([0.2, 0.5, 0.8])
    time_steps = 10
    
    print(f"ä¿¡å·: {signals}")
    print()
    
    # æ³Šæ¾ç¼–ç ï¼ˆå¤šæ¬¡é‡å¤ï¼‰
    torch.manual_seed(42)
    x_expanded = signals.repeat_interleave(time_steps).view(len(signals), time_steps)
    poisson_spikes = simple_poisson_encode(x_expanded)
    
    # å»¶è¿Ÿç¼–ç 
    latency_spikes = simple_latency_encode(signals, time_steps)
    
    print("æ³Šæ¾ç¼–ç ç»“æœ:")
    for i, signal in enumerate(signals):
        pattern = ''.join(['â–ˆ' if s > 0 else 'Â·' for s in poisson_spikes[i]])
        rate = poisson_spikes[i].mean().item()
        print(f"{signal:.1f}: {pattern} (ç‡={rate:.2f})")
    
    print("\nå»¶è¿Ÿç¼–ç ç»“æœ:")
    for i, signal in enumerate(signals):
        pattern = ''.join(['â–ˆ' if s > 0 else 'Â·' for s in latency_spikes[i]])
        spike_time = torch.argmax(latency_spikes[i]).item()
        print(f"{signal:.1f}: {pattern} (æ—¶é—´={spike_time})")
    
    # åŠŸè€—å¯¹æ¯”
    poisson_total_spikes = poisson_spikes.sum().item()
    latency_total_spikes = latency_spikes.sum().item()
    
    print(f"\nåŠŸè€—å¯¹æ¯”:")
    print(f"æ³Šæ¾ç¼–ç æ€»è„‰å†²æ•°: {poisson_total_spikes}")
    print(f"å»¶è¿Ÿç¼–ç æ€»è„‰å†²æ•°: {latency_total_spikes}")
    print(f"å»¶è¿Ÿç¼–ç åŠŸè€—é™ä½: {(1 - latency_total_spikes/poisson_total_spikes)*100:.1f}%")
    
    return True

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 50)
    print("ğŸš€ ç®€åŒ–å»¶è¿Ÿç¼–ç æµ‹è¯•å¥—ä»¶")
    print("=" * 50)
    
    tests = [
        # test_basic_functionality,
        # test_encoding_properties,
        # test_batch_processing,
        # test_noise_robustness,
        visualize_encoding,
        # compare_with_poisson
    ]
    
    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"ğŸ’¥ æµ‹è¯•å¤±è´¥: {e}")
            results.append(False)
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 50)
    passed = sum(results)
    total = len(results)
    print(f"é€šè¿‡: {passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å»¶è¿Ÿç¼–ç å®ç°æ­£ç¡®ã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")

if __name__ == "__main__":
    run_all_tests()